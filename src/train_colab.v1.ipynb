{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PO9R7seabN6",
        "outputId": "fb5a8bbb-ee80-4b35-cbd0-6469fe200fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Đã thiết lập môi trường thành công!\n"
          ]
        }
      ],
      "source": [
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Cài đặt unrar (bắt buộc để giải nén file .rar)\n",
        "!apt-get install unrar\n",
        "\n",
        "# 3. Tạo thư mục làm việc tạm thời trên Colab\n",
        "import os\n",
        "if not os.path.exists('/content/project'):\n",
        "    os.makedirs('/content/project')\n",
        "os.chdir('/content/project') # Chuyển thư mục làm việc về đây\n",
        "print(\"Đã thiết lập môi trường thành công!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMYIOVZ4btrd",
        "outputId": "3bd948af-93f2-40c3-b717-a91678bc59ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing layers.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# LAYERS.PY\n",
        "# ==========================================\n",
        "%%writefile layers.py\n",
        "import numpy as np\n",
        "\n",
        "class Conv:\n",
        "    def __init__(self, num_filters, filter_size=3):\n",
        "        self.num_filters = num_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.filters = np.random.randn(num_filters, filter_size, filter_size) / (filter_size * filter_size)\n",
        "\n",
        "    def iterate_regions(self, image):\n",
        "        h, w = image.shape\n",
        "        for i in range(h - self.filter_size + 1):\n",
        "            for j in range(w - self.filter_size + 1):\n",
        "                im_region = image[i:(i + self.filter_size), j:(j + self.filter_size)]\n",
        "                yield im_region, i, j\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.last_input = input_data\n",
        "        h, w = input_data.shape\n",
        "        output_h = h - self.filter_size + 1\n",
        "        output_w = w - self.filter_size + 1\n",
        "        output = np.zeros((output_h, output_w, self.num_filters))\n",
        "        for im_region, i, j in self.iterate_regions(input_data):\n",
        "            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
        "        return output\n",
        "\n",
        "    def backprop(self, d_l_d_out, learn_rate):\n",
        "        d_l_d_filters = np.zeros(self.filters.shape)\n",
        "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
        "            for f in range(self.num_filters):\n",
        "                d_l_d_filters[f] += d_l_d_out[i, j, f] * im_region\n",
        "        self.filters -= learn_rate * d_l_d_filters\n",
        "        return None\n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, input_data):\n",
        "        self.last_input = input_data\n",
        "        return np.maximum(0, input_data)\n",
        "    def backprop(self, d_l_d_out):\n",
        "        return d_l_d_out * (self.last_input > 0)\n",
        "\n",
        "class MaxPool:\n",
        "    def __init__(self, pool_size=2, stride=2):\n",
        "        self.pool_size = pool_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def iterate_regions(self, image):\n",
        "        h, w, num_filters = image.shape\n",
        "        new_h = (h - self.pool_size) // self.stride + 1\n",
        "        new_w = (w - self.pool_size) // self.stride + 1\n",
        "        for i in range(new_h):\n",
        "            for j in range(new_w):\n",
        "                im_region = image[(i * self.stride):(i * self.stride + self.pool_size),\n",
        "                                  (j * self.stride):(j * self.stride + self.pool_size)]\n",
        "                yield im_region, i, j\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.last_input = input_data\n",
        "        h, w, num_filters = input_data.shape\n",
        "        output_h = (h - self.pool_size) // self.stride + 1\n",
        "        output_w = (w - self.pool_size) // self.stride + 1\n",
        "        output = np.zeros((output_h, output_w, num_filters))\n",
        "        for im_region, i, j in self.iterate_regions(input_data):\n",
        "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
        "        return output\n",
        "\n",
        "    def backprop(self, d_l_d_out):\n",
        "        d_l_d_input = np.zeros(self.last_input.shape)\n",
        "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
        "            h_r, w_r, num_filters_r = im_region.shape\n",
        "            amax = np.amax(im_region, axis=(0, 1))\n",
        "            for r_i in range(h_r):\n",
        "                for r_j in range(w_r):\n",
        "                    for f_k in range(num_filters_r):\n",
        "                        if im_region[r_i, r_j, f_k] == amax[f_k]:\n",
        "                            input_i = i * self.stride + r_i\n",
        "                            input_j = j * self.stride + r_j\n",
        "                            d_l_d_input[input_i, input_j, f_k] += d_l_d_out[i, j, f_k]\n",
        "        return d_l_d_input\n",
        "\n",
        "class Flatten:\n",
        "    def forward(self, input_data):\n",
        "        self.last_input_shape = input_data.shape\n",
        "        return input_data.flatten()\n",
        "    def backprop(self, d_l_d_out):\n",
        "        return d_l_d_out.reshape(self.last_input_shape)\n",
        "\n",
        "class Dense:\n",
        "    def __init__(self, input_len, output_len):\n",
        "        self.weights = np.random.randn(input_len, output_len) / np.sqrt(input_len)\n",
        "        self.biases = np.zeros(output_len)\n",
        "    def forward(self, input_data):\n",
        "        self.last_input = input_data\n",
        "        return np.dot(input_data, self.weights) + self.biases\n",
        "    def backprop(self, d_l_d_out, learn_rate):\n",
        "        d_l_d_weights = np.outer(self.last_input, d_l_d_out)\n",
        "        d_l_d_biases = d_l_d_out\n",
        "        d_l_d_input = np.dot(d_l_d_out, self.weights.T)\n",
        "        self.weights -= learn_rate * d_l_d_weights\n",
        "        self.biases -= learn_rate * d_l_d_biases\n",
        "        return d_l_d_input\n",
        "\n",
        "class Dropout:\n",
        "    def __init__(self, rate):\n",
        "        self.rate = rate\n",
        "        self.mask = None\n",
        "    def forward(self, input_data, training=True):\n",
        "        if training:\n",
        "            self.mask = (np.random.rand(*input_data.shape) > self.rate) / (1.0 - self.rate)\n",
        "            return input_data * self.mask\n",
        "        return input_data\n",
        "    def backprop(self, d_l_d_out):\n",
        "        return d_l_d_out * self.mask\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, input_data):\n",
        "        self.last_input_logits = input_data\n",
        "        exp_shifted = np.exp(input_data - np.max(input_data, axis=-1, keepdims=True))\n",
        "        self.last_output_probs = exp_shifted / np.sum(exp_shifted, axis=-1, keepdims=True)\n",
        "        return self.last_output_probs\n",
        "    def backprop(self, d_l_d_out_probs):\n",
        "        p = self.last_output_probs\n",
        "        return p * (d_l_d_out_probs - np.sum(d_l_d_out_probs * p, axis=-1, keepdims=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL1lGpMwmkYe",
        "outputId": "612c822c-06ee-4f06-b5b4-436d8aa4763c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# MODEL.PY\n",
        "# ==========================================\n",
        "%%writefile model.py\n",
        "import numpy as np\n",
        "import os\n",
        "from layers import Conv, ReLU, MaxPool, Flatten, Dense, Dropout, Softmax\n",
        "\n",
        "class CNNModel:\n",
        "    def __init__(self, input_shape=(28, 28), num_classes=10,\n",
        "                 conv_filters=8, conv_kernel_size=3,\n",
        "                 pool_size=2, pool_stride=2,\n",
        "                 dense1_nodes=128, dropout_rate=0.5):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.conv_filters = conv_filters\n",
        "        self.conv_kernel_size = conv_kernel_size\n",
        "        self.pool_size = pool_size\n",
        "        self.pool_stride = pool_stride\n",
        "        self.dense1_nodes = dense1_nodes\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.conv1 = Conv(num_filters=self.conv_filters, filter_size=self.conv_kernel_size)\n",
        "        self.relu1 = ReLU()\n",
        "        self.pool1 = MaxPool(pool_size=self.pool_size, stride=self.pool_stride)\n",
        "        self.flatten_layer = Flatten()\n",
        "\n",
        "        conv_out_h = self.input_shape[0] - self.conv_kernel_size + 1\n",
        "        conv_out_w = self.input_shape[1] - self.conv_kernel_size + 1\n",
        "        pool_out_h = (conv_out_h - self.pool_size) // self.pool_stride + 1\n",
        "        pool_out_w = (conv_out_w - self.pool_size) // self.pool_stride + 1\n",
        "        self.flattened_size = pool_out_h * pool_out_w * self.conv_filters\n",
        "\n",
        "        self.dense1 = Dense(input_len=self.flattened_size, output_len=self.dense1_nodes)\n",
        "        self.relu2 = ReLU()\n",
        "        self.dropout1 = Dropout(rate=self.dropout_rate)\n",
        "        self.dense2 = Dense(input_len=self.dense1_nodes, output_len=self.num_classes)\n",
        "        self.softmax_activation = Softmax()\n",
        "\n",
        "    def forward(self, image, training=True):\n",
        "        img_processed = image - 0.5\n",
        "        out = self.conv1.forward(img_processed)\n",
        "        out = self.relu1.forward(out)\n",
        "        out = self.pool1.forward(out)\n",
        "        out = self.flatten_layer.forward(out)\n",
        "        out = self.dense1.forward(out)\n",
        "        out = self.relu2.forward(out)\n",
        "        out = self.dropout1.forward(out, training=training)\n",
        "        logits = self.dense2.forward(out)\n",
        "        probs = self.softmax_activation.forward(logits)\n",
        "        return probs, logits\n",
        "\n",
        "    def save_model(self, path, idx_to_class_map):\n",
        "        try:\n",
        "            os.makedirs(os.path.dirname(path) or '.', exist_ok=True)\n",
        "            params_to_save = {\n",
        "                'img_h': self.input_shape[0], 'img_w': self.input_shape[1],\n",
        "                'num_model_classes': self.num_classes, 'conv_filters_count': self.conv_filters,\n",
        "                'conv_kernel_size': self.conv_kernel_size, 'pool_size': self.pool_size,\n",
        "                'pool_stride': self.pool_stride, 'dense1_nodes': self.dense1_nodes,\n",
        "                'dropout_rate': self.dropout_rate, 'conv1_filters': self.conv1.filters,\n",
        "                'dense1_weights': self.dense1.weights, 'dense1_biases': self.dense1.biases,\n",
        "                'dense2_weights': self.dense2.weights, 'dense2_biases': self.dense2.biases,\n",
        "                'idx_to_class_map': np.array(list(idx_to_class_map.items()), dtype=object)\n",
        "            }\n",
        "            np.savez(path, **params_to_save)\n",
        "            print(f\"[SUCCESS] Saved model: {path}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Save failed: {e}\")\n",
        "            return False\n",
        "\n",
        "    @staticmethod\n",
        "    def load_model(path):\n",
        "        if not os.path.exists(path): return None, None\n",
        "        try:\n",
        "            data = np.load(path, allow_pickle=True)\n",
        "            model = CNNModel(\n",
        "                input_shape=(int(data['img_h']), int(data['img_w'])),\n",
        "                num_classes=int(data['num_model_classes']),\n",
        "                conv_filters=int(data['conv_filters_count']),\n",
        "                conv_kernel_size=int(data['conv_kernel_size']),\n",
        "                pool_size=int(data['pool_size']), pool_stride=int(data['pool_stride']),\n",
        "                dense1_nodes=int(data['dense1_nodes']), dropout_rate=float(data['dropout_rate'])\n",
        "            )\n",
        "            model.conv1.filters = data['conv1_filters']\n",
        "            model.dense1.weights = data['dense1_weights']\n",
        "            model.dense1.biases = data['dense1_biases']\n",
        "            model.dense2.weights = data['dense2_weights']\n",
        "            model.dense2.biases = data['dense2_biases']\n",
        "            idx_to_class_map = {int(item[0]): item[1] for item in data['idx_to_class_map']}\n",
        "            return model, idx_to_class_map\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Load failed: {e}\")\n",
        "            return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvPrvy8hm2dj",
        "outputId": "483f9852-694b-487e-89d3-dd75ae56ac02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing input.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# INPUT.PY\n",
        "# ==========================================\n",
        "%%writefile input.py\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image as PILImage\n",
        "import subprocess\n",
        "\n",
        "def unzip_dataset(rar_path, unzip_dir):\n",
        "    if not os.path.exists(unzip_dir): os.makedirs(unzip_dir)\n",
        "    if not os.path.exists(rar_path): return False\n",
        "    print(f\"Unzipping {rar_path}...\")\n",
        "    try:\n",
        "        subprocess.run(['unrar', 'x', '-o+', rar_path, unzip_dir + os.sep],\n",
        "                       capture_output=True, check=True)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Unzip failed: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_custom_data(base_dir, target_size=(28, 28), max_images_per_class=None):\n",
        "    images, labels = [], []\n",
        "    if not os.path.exists(base_dir): return np.array([]), np.array([]), 0, {}, {}\n",
        "\n",
        "    class_names = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
        "    class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "    idx_to_class = {i: name for name, i in class_to_idx.items()}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(base_dir, class_name)\n",
        "        files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        if max_images_per_class: files = files[:max_images_per_class]\n",
        "\n",
        "        for fname in files:\n",
        "            try:\n",
        "                img = PILImage.open(os.path.join(class_dir, fname)).convert('L')\n",
        "                img = img.resize(target_size, PILImage.LANCZOS)\n",
        "                img_arr = np.array(img, dtype=np.float32) / 255.0\n",
        "                images.append(img_arr)\n",
        "                labels.append(class_to_idx[class_name])\n",
        "            except: continue\n",
        "\n",
        "    return np.array(images, dtype=np.float32), np.array(labels, dtype=np.int32), len(class_names), idx_to_class, class_to_idx\n",
        "\n",
        "def split_train_val(images, labels, val_split=0.2, random_seed=42):\n",
        "    np.random.seed(random_seed)\n",
        "    indices = np.random.permutation(len(images))\n",
        "    split_idx = int(len(images) * (1 - val_split))\n",
        "    train_idx, val_idx = indices[:split_idx], indices[split_idx:]\n",
        "    return images[train_idx], labels[train_idx], images[val_idx], labels[val_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szPUP47gb3aB",
        "outputId": "db04fa63-c14b-46bc-96b3-6561195658a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# TRAIN.PY\n",
        "# ==========================================\n",
        "%%writefile train.py\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from input import load_custom_data, unzip_dataset, split_train_val\n",
        "from model import CNNModel\n",
        "\n",
        "# ===== CẤU HÌNH =====\n",
        "# Đường dẫn tới file RAR trên Google Drive\n",
        "RAR_PATH = \"/content/drive/MyDrive/Colab/dataset/CNN_Dataset.v2.rar\"\n",
        "\n",
        "# Thư mục để giải nén ra trên Colab\n",
        "UNZIP_DIR = \"/content/dataset\"\n",
        "\n",
        "# Nơi lưu model sau khi train\n",
        "MODEL_SAVE_DIR = \"/content/drive/MyDrive/Colab/model_output\"\n",
        "MODEL_NAME = \"my_cnn_model.v2.npz\"\n",
        "MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, MODEL_NAME)\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 15           # Số vòng lặp training\n",
        "LEARNING_RATE = 0.005  # Tốc độ học\n",
        "VAL_SPLIT = 0.2        # Dành 20% dữ liệu để kiểm tra (Validation)\n",
        "\n",
        "def find_data_root(start_dir):\n",
        "    \"\"\"\n",
        "    Hàm thông minh tự tìm thư mục chứa các class (0, 1, A, B...)\n",
        "    để tránh lỗi sai đường dẫn sau khi giải nén.\n",
        "    \"\"\"\n",
        "    # Kiểm tra ngay thư mục gốc\n",
        "    subdirs = [d for d in os.listdir(start_dir) if os.path.isdir(os.path.join(start_dir, d))]\n",
        "    # Nếu thấy folder tên là \"0\" hoặc \"A\" ngay đây thì đúng là nó\n",
        "    if \"0\" in subdirs or \"A\" in subdirs:\n",
        "        return start_dir\n",
        "\n",
        "    # Nếu không, thử đi sâu vào 1 cấp (trường hợp giải nén ra folder cha)\n",
        "    for d in subdirs:\n",
        "        next_level = os.path.join(start_dir, d)\n",
        "        sub_subdirs = [s for s in os.listdir(next_level) if os.path.isdir(os.path.join(next_level, s))]\n",
        "        if \"0\" in sub_subdirs or \"A\" in sub_subdirs:\n",
        "            return next_level\n",
        "\n",
        "    return start_dir # Fallback\n",
        "\n",
        "def plot_history(history, save_dir):\n",
        "    \"\"\"Vẽ biểu đồ và lưu lại\"\"\"\n",
        "    if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss', color='blue')\n",
        "    plt.plot(history['val_loss'], label='Val Loss', color='red')\n",
        "    plt.title('Training & Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train Acc', color='blue')\n",
        "    plt.plot(history['val_acc'], label='Val Acc', color='red')\n",
        "    plt.title('Training & Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    chart_path = os.path.join(save_dir, 'training_result_chart.png')\n",
        "    plt.savefig(chart_path)\n",
        "    print(f\"\\n[CHART] Đã lưu biểu đồ đánh giá tại: {chart_path}\")\n",
        "    # plt.show()\n",
        "\n",
        "def train_step(model, img, lbl, lr):\n",
        "    # Forward\n",
        "    probs, _ = model.forward(img, training=True)\n",
        "\n",
        "    # Tính Loss\n",
        "    loss = -np.log(probs[lbl] + 1e-9)\n",
        "    acc = 1 if np.argmax(probs) == lbl else 0\n",
        "\n",
        "    # Backward\n",
        "    grad_logits = probs.copy()\n",
        "    grad_logits[lbl] -= 1\n",
        "\n",
        "    # Truyền ngược (Backpropagation)\n",
        "    d = model.dense2.backprop(grad_logits, lr)\n",
        "    d = model.dropout1.backprop(d)\n",
        "    d = model.relu2.backprop(d)\n",
        "    d = model.dense1.backprop(d, lr)\n",
        "    d = model.flatten_layer.backprop(d)\n",
        "    d = model.pool1.backprop(d)\n",
        "    d = model.relu1.backprop(d)\n",
        "    model.conv1.backprop(d, lr)\n",
        "\n",
        "    return loss, acc\n",
        "\n",
        "def evaluate(model, images, labels):\n",
        "    \"\"\"Đánh giá model trên tập Validation\"\"\"\n",
        "    loss_sum, correct = 0, 0\n",
        "    for img, lbl in zip(images, labels):\n",
        "        probs, _ = model.forward(img, training=False)\n",
        "        loss_sum += -np.log(probs[lbl] + 1e-9)\n",
        "        if np.argmax(probs) == lbl: correct += 1\n",
        "    return loss_sum/len(images), (correct/len(images))*100\n",
        "\n",
        "def main():\n",
        "    print(\"=== BẮT ĐẦU QUÁ TRÌNH TRAINING ===\")\n",
        "\n",
        "    # 1. Giải nén Dataset\n",
        "    if not unzip_dataset(RAR_PATH, UNZIP_DIR):\n",
        "        print(f\"[LỖI] Không thể giải nén file: {RAR_PATH}\")\n",
        "        print(\"Hãy kiểm tra kỹ đường dẫn file RAR trên Google Drive của bạn.\")\n",
        "        return\n",
        "\n",
        "    # 2. Xác định thư mục chứa data\n",
        "    print(\"[INFO] Đang tìm thư mục dữ liệu...\")\n",
        "    data_dir = find_data_root(UNZIP_DIR)\n",
        "    print(f\"[INFO] Đã tìm thấy dữ liệu tại: {data_dir}\")\n",
        "\n",
        "    # 3. Load toàn bộ dữ liệu\n",
        "    print(f\"[INFO] Đang load ảnh và nhãn từ {data_dir}...\")\n",
        "    # Lưu ý: dataset của bạn không chia train/test nên ta load hết 1 cục\n",
        "    images, labels, num_classes, idx_to_class, _ = load_custom_data(data_dir)\n",
        "\n",
        "    if len(images) == 0:\n",
        "        print(f\"[LỖI] Không tìm thấy ảnh nào! Hãy kiểm tra lại file nén.\")\n",
        "        return\n",
        "\n",
        "    # 4. Chia Train / Validation tự động (80% train, 20% val)\n",
        "    print(f\"[INFO] Đang chia dữ liệu (Validation Split = {VAL_SPLIT})...\")\n",
        "    train_X, train_y, val_X, val_y = split_train_val(images, labels, val_split=VAL_SPLIT)\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Tổng số Class: {num_classes}\")\n",
        "    print(f\"Dữ liệu Train: {len(train_X)} ảnh\")\n",
        "    print(f\"Dữ liệu Valid: {len(val_X)} ảnh\")\n",
        "    print(f\"Kích thước ảnh input: {train_X[0].shape}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # 5. Khởi tạo Model\n",
        "    model = CNNModel(input_shape=train_X[0].shape, num_classes=num_classes)\n",
        "\n",
        "    # Lưu lịch sử để vẽ biểu đồ\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    # 6. Training Loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        # Xáo trộn dữ liệu mỗi epoch\n",
        "        perm = np.random.permutation(len(train_X))\n",
        "        train_X, train_y = train_X[perm], train_y[perm]\n",
        "\n",
        "        epoch_loss, epoch_acc = 0, 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train từng ảnh (SGD)\n",
        "        for i, (img, lbl) in enumerate(zip(train_X, train_y)):\n",
        "            l, a = train_step(model, img, lbl, LEARNING_RATE)\n",
        "            epoch_loss += l\n",
        "            epoch_acc += a\n",
        "\n",
        "            # In tiến độ mỗi 200 ảnh\n",
        "            if i % 200 == 0:\n",
        "                percent = (i / len(train_X)) * 100\n",
        "                print(f\"\\r  Epoch {epoch+1} Running... {percent:.1f}%\", end=\"\")\n",
        "\n",
        "        # Tổng kết Epoch\n",
        "        train_avg_loss = epoch_loss / len(train_X)\n",
        "        train_avg_acc = (epoch_acc / len(train_X)) * 100\n",
        "\n",
        "        # Đánh giá trên tập Validation\n",
        "        val_loss, val_acc = evaluate(model, val_X, val_y)\n",
        "\n",
        "        # Lưu history\n",
        "        history['train_loss'].append(train_avg_loss)\n",
        "        history['train_acc'].append(train_avg_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"\\rEpoch {epoch+1:02d}/{EPOCHS} | \"\n",
        "              f\"Train Loss: {train_avg_loss:.4f} Acc: {train_avg_acc:.2f}% | \"\n",
        "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}% | \"\n",
        "              f\"Time: {time.time()-start_time:.1f}s\")\n",
        "\n",
        "    # 7. Lưu Model và Biểu đồ\n",
        "    print(\"\\n[INFO] Đang lưu kết quả...\")\n",
        "    model.save_model(MODEL_SAVE_PATH, idx_to_class)\n",
        "    plot_history(history, MODEL_SAVE_DIR)\n",
        "    print(\"\\n=== HOÀN TẤT ===\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlK5WUZCb6fa",
        "outputId": "19fe5449-b335-4466-9502-516c08da7a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BẮT ĐẦU QUÁ TRÌNH TRAINING ===\n",
            "Unzipping /content/drive/MyDrive/Colab/dataset/CNN_Dataset.v2.rar...\n",
            "[INFO] Đang tìm thư mục dữ liệu...\n",
            "[INFO] Đã tìm thấy dữ liệu tại: /content/dataset\n",
            "[INFO] Đang load ảnh và nhãn từ /content/dataset...\n",
            "[INFO] Đang chia dữ liệu (Validation Split = 0.2)...\n",
            "--------------------------------------------------\n",
            "Tổng số Class: 31\n",
            "Dữ liệu Train: 12400 ảnh\n",
            "Dữ liệu Valid: 3100 ảnh\n",
            "Kích thước ảnh input: (28, 28)\n",
            "--------------------------------------------------\n",
            "Epoch 01/15 | Train Loss: 1.6069 Acc: 51.44% | Val Loss: 0.5151 Acc: 86.03% | Time: 503.7s\n",
            "Epoch 02/15 | Train Loss: 0.6151 Acc: 80.05% | Val Loss: 0.1814 Acc: 94.97% | Time: 500.2s\n",
            "Epoch 03/15 | Train Loss: 0.3982 Acc: 86.63% | Val Loss: 0.1195 Acc: 96.97% | Time: 498.0s\n",
            "Epoch 04/15 | Train Loss: 0.2862 Acc: 90.54% | Val Loss: 0.0755 Acc: 98.42% | Time: 496.0s\n",
            "Epoch 05/15 | Train Loss: 0.2328 Acc: 92.00% | Val Loss: 0.0566 Acc: 98.52% | Time: 495.2s\n",
            "Epoch 06/15 | Train Loss: 0.1930 Acc: 93.69% | Val Loss: 0.0507 Acc: 98.68% | Time: 499.2s\n",
            "Epoch 07/15 | Train Loss: 0.1626 Acc: 94.44% | Val Loss: 0.0420 Acc: 98.81% | Time: 499.9s\n",
            "Epoch 08/15 | Train Loss: 0.1504 Acc: 94.88% | Val Loss: 0.0463 Acc: 98.77% | Time: 494.3s\n",
            "Epoch 09/15 | Train Loss: 0.1189 Acc: 95.98% | Val Loss: 0.0331 Acc: 99.23% | Time: 492.8s\n",
            "Epoch 10/15 | Train Loss: 0.1212 Acc: 95.98% | Val Loss: 0.0350 Acc: 98.90% | Time: 493.8s\n",
            "Epoch 11/15 | Train Loss: 0.1038 Acc: 96.52% | Val Loss: 0.0394 Acc: 98.87% | Time: 493.9s\n",
            "Epoch 12/15 | Train Loss: 0.1047 Acc: 96.62% | Val Loss: 0.0261 Acc: 99.32% | Time: 495.1s\n",
            "Epoch 13/15 | Train Loss: 0.0978 Acc: 96.84% | Val Loss: 0.0268 Acc: 99.32% | Time: 492.2s\n",
            "Epoch 14/15 | Train Loss: 0.0915 Acc: 96.95% | Val Loss: 0.0241 Acc: 99.61% | Time: 491.8s\n",
            "Epoch 15/15 | Train Loss: 0.0842 Acc: 97.20% | Val Loss: 0.0243 Acc: 99.45% | Time: 494.8s\n",
            "\n",
            "[INFO] Đang lưu kết quả...\n",
            "[SUCCESS] Saved model: /content/drive/MyDrive/Colab/model_output/my_cnn_model.v2.npz\n",
            "\n",
            "[CHART] Đã lưu biểu đồ đánh giá tại: /content/drive/MyDrive/Colab/model_output/training_result_chart.png\n",
            "\n",
            "=== HOÀN TẤT ===\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image as PILImage\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from model import CNNModel\n",
        "import io\n",
        "\n",
        "# ===== CẤU HÌNH =====\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab/model_output/my_cnn_model.v2.npz\"\n",
        "\n",
        "def predict_uploaded_image():\n",
        "    # 1. Load Model trước\n",
        "    model, idx_to_class = CNNModel.load_model(MODEL_PATH)\n",
        "    if model is None: return\n",
        "\n",
        "    # 2. Cho user upload file\n",
        "    print(\"Hay chon mot file anh chu cai (A-Z, 0-9) tu may tinh cua ban:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        # 3. Xử lý ảnh upload\n",
        "        image_data = uploaded[fn]\n",
        "        img_pil = PILImage.open(io.BytesIO(image_data)).convert('L') # Chuyển sang đen trắng\n",
        "\n",
        "        # Resize về đúng kích thước model đã học (28x28)\n",
        "        img_resized = img_pil.resize((28, 28), PILImage.LANCZOS)\n",
        "        img_array = np.array(img_resized, dtype=np.float32) / 255.0 # Normalize\n",
        "\n",
        "        # 4. Dự đoán\n",
        "        probs, _ = model.forward(img_array, training=False)\n",
        "        pred_idx = np.argmax(probs)\n",
        "        pred_label = idx_to_class[pred_idx]\n",
        "        confidence = probs[pred_idx] * 100\n",
        "\n",
        "        # 5. Hiển thị kết quả\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        plt.imshow(img_array, cmap='gray')\n",
        "        plt.title(f\"Dự đoán: {pred_label}\\nĐộ tin cậy: {confidence:.1f}%\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        print(f\"-> File '{fn}' được nhận diện là: {pred_label}\")\n",
        "\n",
        "# Chạy hàm test upload\n",
        "predict_uploaded_image()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "yid1lUGkDeWF",
        "outputId": "e553449c-794f-45c3-98a5-1bd30231b63c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay chon mot file anh chu cai (A-Z, 0-9) tu may tinh cua ban:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3343e048-9a4a-4e13-9a2c-3257cce9127e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3343e048-9a4a-4e13-9a2c-3257cce9127e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mb_161_char_7.jpg to mb_161_char_7.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> File 'mb_161_char_7.jpg' được nhận diện là: S\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}