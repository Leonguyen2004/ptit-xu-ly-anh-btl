{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23377,"status":"ok","timestamp":1763674542417,"user":{"displayName":"Lộc “Leopard” Nguyễn","userId":"17234762684403330361"},"user_tz":-420},"id":"7PO9R7seabN6","outputId":"27698924-da21-433e-d563-58de4a6c4b72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","unrar is already the newest version (1:6.1.5-1ubuntu0.1).\n","0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n","Đã thiết lập môi trường thành công!\n"]}],"source":["# 1. Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 2. Cài đặt unrar (bắt buộc để giải nén file .rar)\n","!apt-get install unrar\n","\n","# 3. Tạo thư mục làm việc tạm thời trên Colab\n","import os\n","if not os.path.exists('/content/project'):\n","    os.makedirs('/content/project')\n","os.chdir('/content/project') # Chuyển thư mục làm việc về đây\n","print(\"Đã thiết lập môi trường thành công!\")"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1763674517501,"user":{"displayName":"Lộc “Leopard” Nguyễn","userId":"17234762684403330361"},"user_tz":-420},"id":"PMYIOVZ4btrd","outputId":"be5eee9b-2459-4233-8d96-5de91f1b81ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing layers.py\n"]}],"source":["# ==========================================\n","# LAYERS.PY\n","# ==========================================\n","%%writefile layers.py\n","import numpy as np\n","\n","class Conv:\n","    def __init__(self, num_filters, filter_size=3):\n","        self.num_filters = num_filters\n","        self.filter_size = filter_size\n","        self.filters = np.random.randn(num_filters, filter_size, filter_size) / (filter_size * filter_size)\n","\n","    def iterate_regions(self, image):\n","        h, w = image.shape\n","        for i in range(h - self.filter_size + 1):\n","            for j in range(w - self.filter_size + 1):\n","                im_region = image[i:(i + self.filter_size), j:(j + self.filter_size)]\n","                yield im_region, i, j\n","\n","    def forward(self, input_data):\n","        self.last_input = input_data\n","        h, w = input_data.shape\n","        output_h = h - self.filter_size + 1\n","        output_w = w - self.filter_size + 1\n","        output = np.zeros((output_h, output_w, self.num_filters))\n","        for im_region, i, j in self.iterate_regions(input_data):\n","            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n","        return output\n","\n","    def backprop(self, d_l_d_out, learn_rate):\n","        d_l_d_filters = np.zeros(self.filters.shape)\n","        for im_region, i, j in self.iterate_regions(self.last_input):\n","            for f in range(self.num_filters):\n","                d_l_d_filters[f] += d_l_d_out[i, j, f] * im_region\n","        self.filters -= learn_rate * d_l_d_filters\n","        return None\n","\n","class ReLU:\n","    def forward(self, input_data):\n","        self.last_input = input_data\n","        return np.maximum(0, input_data)\n","    def backprop(self, d_l_d_out):\n","        return d_l_d_out * (self.last_input > 0)\n","\n","class MaxPool:\n","    def __init__(self, pool_size=2, stride=2):\n","        self.pool_size = pool_size\n","        self.stride = stride\n","\n","    def iterate_regions(self, image):\n","        h, w, num_filters = image.shape\n","        new_h = (h - self.pool_size) // self.stride + 1\n","        new_w = (w - self.pool_size) // self.stride + 1\n","        for i in range(new_h):\n","            for j in range(new_w):\n","                im_region = image[(i * self.stride):(i * self.stride + self.pool_size),\n","                                  (j * self.stride):(j * self.stride + self.pool_size)]\n","                yield im_region, i, j\n","\n","    def forward(self, input_data):\n","        self.last_input = input_data\n","        h, w, num_filters = input_data.shape\n","        output_h = (h - self.pool_size) // self.stride + 1\n","        output_w = (w - self.pool_size) // self.stride + 1\n","        output = np.zeros((output_h, output_w, num_filters))\n","        for im_region, i, j in self.iterate_regions(input_data):\n","            output[i, j] = np.amax(im_region, axis=(0, 1))\n","        return output\n","\n","    def backprop(self, d_l_d_out):\n","        d_l_d_input = np.zeros(self.last_input.shape)\n","        for im_region, i, j in self.iterate_regions(self.last_input):\n","            h_r, w_r, num_filters_r = im_region.shape\n","            amax = np.amax(im_region, axis=(0, 1))\n","            for r_i in range(h_r):\n","                for r_j in range(w_r):\n","                    for f_k in range(num_filters_r):\n","                        if im_region[r_i, r_j, f_k] == amax[f_k]:\n","                            input_i = i * self.stride + r_i\n","                            input_j = j * self.stride + r_j\n","                            d_l_d_input[input_i, input_j, f_k] += d_l_d_out[i, j, f_k]\n","        return d_l_d_input\n","\n","class Flatten:\n","    def forward(self, input_data):\n","        self.last_input_shape = input_data.shape\n","        return input_data.flatten()\n","    def backprop(self, d_l_d_out):\n","        return d_l_d_out.reshape(self.last_input_shape)\n","\n","class Dense:\n","    def __init__(self, input_len, output_len):\n","        self.weights = np.random.randn(input_len, output_len) / np.sqrt(input_len)\n","        self.biases = np.zeros(output_len)\n","    def forward(self, input_data):\n","        self.last_input = input_data\n","        return np.dot(input_data, self.weights) + self.biases\n","    def backprop(self, d_l_d_out, learn_rate):\n","        d_l_d_weights = np.outer(self.last_input, d_l_d_out)\n","        d_l_d_biases = d_l_d_out\n","        d_l_d_input = np.dot(d_l_d_out, self.weights.T)\n","        self.weights -= learn_rate * d_l_d_weights\n","        self.biases -= learn_rate * d_l_d_biases\n","        return d_l_d_input\n","\n","class Dropout:\n","    def __init__(self, rate):\n","        self.rate = rate\n","        self.mask = None\n","    def forward(self, input_data, training=True):\n","        if training:\n","            self.mask = (np.random.rand(*input_data.shape) > self.rate) / (1.0 - self.rate)\n","            return input_data * self.mask\n","        return input_data\n","    def backprop(self, d_l_d_out):\n","        return d_l_d_out * self.mask\n","\n","class Softmax:\n","    def forward(self, input_data):\n","        self.last_input_logits = input_data\n","        exp_shifted = np.exp(input_data - np.max(input_data, axis=-1, keepdims=True))\n","        self.last_output_probs = exp_shifted / np.sum(exp_shifted, axis=-1, keepdims=True)\n","        return self.last_output_probs\n","    def backprop(self, d_l_d_out_probs):\n","        p = self.last_output_probs\n","        return p * (d_l_d_out_probs - np.sum(d_l_d_out_probs * p, axis=-1, keepdims=True))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1763674559237,"user":{"displayName":"Lộc “Leopard” Nguyễn","userId":"17234762684403330361"},"user_tz":-420},"id":"FL1lGpMwmkYe","outputId":"f2992f58-44d1-45cf-c251-79284de5e206"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing model.py\n"]}],"source":["# ==========================================\n","# MODEL.PY\n","# ==========================================\n","%%writefile model.py\n","import numpy as np\n","import os\n","from layers import Conv, ReLU, MaxPool, Flatten, Dense, Dropout, Softmax\n","\n","class CNNModel:\n","    def __init__(self, input_shape=(28, 28), num_classes=10,\n","                 conv_filters=8, conv_kernel_size=3,\n","                 pool_size=2, pool_stride=2,\n","                 dense1_nodes=128, dropout_rate=0.5):\n","        self.input_shape = input_shape\n","        self.num_classes = num_classes\n","        self.conv_filters = conv_filters\n","        self.conv_kernel_size = conv_kernel_size\n","        self.pool_size = pool_size\n","        self.pool_stride = pool_stride\n","        self.dense1_nodes = dense1_nodes\n","        self.dropout_rate = dropout_rate\n","\n","        self.conv1 = Conv(num_filters=self.conv_filters, filter_size=self.conv_kernel_size)\n","        self.relu1 = ReLU()\n","        self.pool1 = MaxPool(pool_size=self.pool_size, stride=self.pool_stride)\n","        self.flatten_layer = Flatten()\n","\n","        conv_out_h = self.input_shape[0] - self.conv_kernel_size + 1\n","        conv_out_w = self.input_shape[1] - self.conv_kernel_size + 1\n","        pool_out_h = (conv_out_h - self.pool_size) // self.pool_stride + 1\n","        pool_out_w = (conv_out_w - self.pool_size) // self.pool_stride + 1\n","        self.flattened_size = pool_out_h * pool_out_w * self.conv_filters\n","\n","        self.dense1 = Dense(input_len=self.flattened_size, output_len=self.dense1_nodes)\n","        self.relu2 = ReLU()\n","        self.dropout1 = Dropout(rate=self.dropout_rate)\n","        self.dense2 = Dense(input_len=self.dense1_nodes, output_len=self.num_classes)\n","        self.softmax_activation = Softmax()\n","\n","    def forward(self, image, training=True):\n","        img_processed = image - 0.5\n","        out = self.conv1.forward(img_processed)\n","        out = self.relu1.forward(out)\n","        out = self.pool1.forward(out)\n","        out = self.flatten_layer.forward(out)\n","        out = self.dense1.forward(out)\n","        out = self.relu2.forward(out)\n","        out = self.dropout1.forward(out, training=training)\n","        logits = self.dense2.forward(out)\n","        probs = self.softmax_activation.forward(logits)\n","        return probs, logits\n","\n","    def save_model(self, path, idx_to_class_map):\n","        try:\n","            os.makedirs(os.path.dirname(path) or '.', exist_ok=True)\n","            params_to_save = {\n","                'img_h': self.input_shape[0], 'img_w': self.input_shape[1],\n","                'num_model_classes': self.num_classes, 'conv_filters_count': self.conv_filters,\n","                'conv_kernel_size': self.conv_kernel_size, 'pool_size': self.pool_size,\n","                'pool_stride': self.pool_stride, 'dense1_nodes': self.dense1_nodes,\n","                'dropout_rate': self.dropout_rate, 'conv1_filters': self.conv1.filters,\n","                'dense1_weights': self.dense1.weights, 'dense1_biases': self.dense1.biases,\n","                'dense2_weights': self.dense2.weights, 'dense2_biases': self.dense2.biases,\n","                'idx_to_class_map': np.array(list(idx_to_class_map.items()), dtype=object)\n","            }\n","            np.savez(path, **params_to_save)\n","            print(f\"[SUCCESS] Saved model: {path}\")\n","            return True\n","        except Exception as e:\n","            print(f\"[ERROR] Save failed: {e}\")\n","            return False\n","\n","    @staticmethod\n","    def load_model(path):\n","        if not os.path.exists(path): return None, None\n","        try:\n","            data = np.load(path, allow_pickle=True)\n","            model = CNNModel(\n","                input_shape=(int(data['img_h']), int(data['img_w'])),\n","                num_classes=int(data['num_model_classes']),\n","                conv_filters=int(data['conv_filters_count']),\n","                conv_kernel_size=int(data['conv_kernel_size']),\n","                pool_size=int(data['pool_size']), pool_stride=int(data['pool_stride']),\n","                dense1_nodes=int(data['dense1_nodes']), dropout_rate=float(data['dropout_rate'])\n","            )\n","            model.conv1.filters = data['conv1_filters']\n","            model.dense1.weights = data['dense1_weights']\n","            model.dense1.biases = data['dense1_biases']\n","            model.dense2.weights = data['dense2_weights']\n","            model.dense2.biases = data['dense2_biases']\n","            idx_to_class_map = {int(item[0]): item[1] for item in data['idx_to_class_map']}\n","            return model, idx_to_class_map\n","        except Exception as e:\n","            print(f\"[ERROR] Load failed: {e}\")\n","            return None, None"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1763674562673,"user":{"displayName":"Lộc “Leopard” Nguyễn","userId":"17234762684403330361"},"user_tz":-420},"id":"wvPrvy8hm2dj","outputId":"f5b3eed6-1760-4b8e-c20c-691ba9af65d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing input.py\n"]}],"source":["# ==========================================\n","# INPUT.PY\n","# ==========================================\n","%%writefile input.py\n","import numpy as np\n","import os\n","from PIL import Image as PILImage\n","import subprocess\n","\n","def unzip_dataset(rar_path, unzip_dir):\n","    if not os.path.exists(unzip_dir): os.makedirs(unzip_dir)\n","    if not os.path.exists(rar_path): return False\n","    print(f\"Unzipping {rar_path}...\")\n","    try:\n","        subprocess.run(['unrar', 'x', '-o+', rar_path, unzip_dir + os.sep],\n","                       capture_output=True, check=True)\n","        return True\n","    except Exception as e:\n","        print(f\"Unzip failed: {e}\")\n","        return False\n","\n","def load_custom_data(base_dir, target_size=(28, 28), max_images_per_class=None):\n","    images, labels = [], []\n","    if not os.path.exists(base_dir): return np.array([]), np.array([]), 0, {}, {}\n","\n","    class_names = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n","    class_to_idx = {name: i for i, name in enumerate(class_names)}\n","    idx_to_class = {i: name for name, i in class_to_idx.items()}\n","\n","    for class_name in class_names:\n","        class_dir = os.path.join(base_dir, class_name)\n","        files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","        if max_images_per_class: files = files[:max_images_per_class]\n","\n","        for fname in files:\n","            try:\n","                img = PILImage.open(os.path.join(class_dir, fname)).convert('L')\n","                img = img.resize(target_size, PILImage.LANCZOS)\n","                img_arr = np.array(img, dtype=np.float32) / 255.0\n","                images.append(img_arr)\n","                labels.append(class_to_idx[class_name])\n","            except: continue\n","\n","    return np.array(images, dtype=np.float32), np.array(labels, dtype=np.int32), len(class_names), idx_to_class, class_to_idx\n","\n","def split_train_val(images, labels, val_split=0.2, random_seed=42):\n","    np.random.seed(random_seed)\n","    indices = np.random.permutation(len(images))\n","    split_idx = int(len(images) * (1 - val_split))\n","    train_idx, val_idx = indices[:split_idx], indices[split_idx:]\n","    return images[train_idx], labels[train_idx], images[val_idx], labels[val_idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1763513966791,"user":{"displayName":"Lộc “Leopard” Nguyễn","userId":"17234762684403330361"},"user_tz":-420},"id":"szPUP47gb3aB","outputId":"1d0d482a-ae78-44bb-b866-d457d1f0417f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting train.py\n"]}],"source":["%%writefile train.py\n","import numpy as np\n","import os\n","import time\n","import matplotlib.pyplot as plt\n","from input import load_custom_data, unzip_dataset, split_train_val\n","from model import CNNModel\n","\n","# ===== CẤU HÌNH =====\n","# Đường dẫn tới file RAR trên Google Drive\n","RAR_PATH = \"/content/drive/MyDrive/Colab/dataset/CNN_letter_Dataset.rar\"\n","\n","# Thư mục để giải nén ra trên Colab\n","UNZIP_DIR = \"/content/dataset\"\n","\n","# Nơi lưu model sau khi train\n","MODEL_SAVE_DIR = \"/content/drive/MyDrive/Colab/model_output\"\n","MODEL_NAME = \"my_cnn_model.npz\"\n","MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, MODEL_NAME)\n","\n","# Hyperparameters\n","EPOCHS = 15            # Số vòng lặp training\n","LEARNING_RATE = 0.005  # Tốc độ học\n","VAL_SPLIT = 0.2        # Dành 20% dữ liệu để kiểm tra (Validation)\n","\n","def find_data_root(start_dir):\n","    \"\"\"\n","    Hàm thông minh tự tìm thư mục chứa các class (0, 1, A, B...)\n","    để tránh lỗi sai đường dẫn sau khi giải nén.\n","    \"\"\"\n","    # Kiểm tra ngay thư mục gốc\n","    subdirs = [d for d in os.listdir(start_dir) if os.path.isdir(os.path.join(start_dir, d))]\n","    # Nếu thấy folder tên là \"0\" hoặc \"A\" ngay đây thì đúng là nó\n","    if \"0\" in subdirs or \"A\" in subdirs:\n","        return start_dir\n","\n","    # Nếu không, thử đi sâu vào 1 cấp (trường hợp giải nén ra folder cha)\n","    for d in subdirs:\n","        next_level = os.path.join(start_dir, d)\n","        sub_subdirs = [s for s in os.listdir(next_level) if os.path.isdir(os.path.join(next_level, s))]\n","        if \"0\" in sub_subdirs or \"A\" in sub_subdirs:\n","            return next_level\n","\n","    return start_dir # Fallback\n","\n","def plot_history(history, save_dir):\n","    \"\"\"Vẽ biểu đồ và lưu lại\"\"\"\n","    if not os.path.exists(save_dir): os.makedirs(save_dir)\n","\n","    plt.figure(figsize=(12, 5))\n","\n","    # Plot Loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history['train_loss'], label='Train Loss', color='blue')\n","    plt.plot(history['val_loss'], label='Val Loss', color='red')\n","    plt.title('Training & Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    # Plot Accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history['train_acc'], label='Train Acc', color='blue')\n","    plt.plot(history['val_acc'], label='Val Acc', color='red')\n","    plt.title('Training & Validation Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.legend()\n","    plt.grid(True)\n","\n","    chart_path = os.path.join(save_dir, 'training_result_chart.png')\n","    plt.savefig(chart_path)\n","    print(f\"\\n[CHART] Đã lưu biểu đồ đánh giá tại: {chart_path}\")\n","    # plt.show()\n","\n","def train_step(model, img, lbl, lr):\n","    # Forward\n","    probs, _ = model.forward(img, training=True)\n","\n","    # Tính Loss\n","    loss = -np.log(probs[lbl] + 1e-9)\n","    acc = 1 if np.argmax(probs) == lbl else 0\n","\n","    # Backward\n","    grad_logits = probs.copy()\n","    grad_logits[lbl] -= 1\n","\n","    # Truyền ngược (Backpropagation)\n","    d = model.dense2.backprop(grad_logits, lr)\n","    d = model.dropout1.backprop(d)\n","    d = model.relu2.backprop(d)\n","    d = model.dense1.backprop(d, lr)\n","    d = model.flatten_layer.backprop(d)\n","    d = model.pool1.backprop(d)\n","    d = model.relu1.backprop(d)\n","    model.conv1.backprop(d, lr)\n","\n","    return loss, acc\n","\n","def evaluate(model, images, labels):\n","    \"\"\"Đánh giá model trên tập Validation\"\"\"\n","    loss_sum, correct = 0, 0\n","    for img, lbl in zip(images, labels):\n","        probs, _ = model.forward(img, training=False)\n","        loss_sum += -np.log(probs[lbl] + 1e-9)\n","        if np.argmax(probs) == lbl: correct += 1\n","    return loss_sum/len(images), (correct/len(images))*100\n","\n","def main():\n","    print(\"=== BẮT ĐẦU QUÁ TRÌNH TRAINING ===\")\n","\n","    # 1. Giải nén Dataset\n","    if not unzip_dataset(RAR_PATH, UNZIP_DIR):\n","        print(f\"[LỖI] Không thể giải nén file: {RAR_PATH}\")\n","        print(\"Hãy kiểm tra kỹ đường dẫn file RAR trên Google Drive của bạn.\")\n","        return\n","\n","    # 2. Xác định thư mục chứa data\n","    print(\"[INFO] Đang tìm thư mục dữ liệu...\")\n","    data_dir = find_data_root(UNZIP_DIR)\n","    print(f\"[INFO] Đã tìm thấy dữ liệu tại: {data_dir}\")\n","\n","    # 3. Load toàn bộ dữ liệu\n","    print(f\"[INFO] Đang load ảnh và nhãn từ {data_dir}...\")\n","    # Lưu ý: dataset của bạn không chia train/test nên ta load hết 1 cục\n","    images, labels, num_classes, idx_to_class, _ = load_custom_data(data_dir)\n","\n","    if len(images) == 0:\n","        print(f\"[LỖI] Không tìm thấy ảnh nào! Hãy kiểm tra lại file nén.\")\n","        return\n","\n","    # 4. Chia Train / Validation tự động (80% train, 20% val)\n","    print(f\"[INFO] Đang chia dữ liệu (Validation Split = {VAL_SPLIT})...\")\n","    train_X, train_y, val_X, val_y = split_train_val(images, labels, val_split=VAL_SPLIT)\n","\n","    print(\"-\" * 50)\n","    print(f\"Tổng số Class: {num_classes}\")\n","    print(f\"Dữ liệu Train: {len(train_X)} ảnh\")\n","    print(f\"Dữ liệu Valid: {len(val_X)} ảnh\")\n","    print(f\"Kích thước ảnh input: {train_X[0].shape}\")\n","    print(\"-\" * 50)\n","\n","    # 5. Khởi tạo Model\n","    model = CNNModel(input_shape=train_X[0].shape, num_classes=num_classes)\n","\n","    # Lưu lịch sử để vẽ biểu đồ\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    # 6. Training Loop\n","    for epoch in range(EPOCHS):\n","        # Xáo trộn dữ liệu mỗi epoch\n","        perm = np.random.permutation(len(train_X))\n","        train_X, train_y = train_X[perm], train_y[perm]\n","\n","        epoch_loss, epoch_acc = 0, 0\n","        start_time = time.time()\n","\n","        # Train từng ảnh (SGD)\n","        for i, (img, lbl) in enumerate(zip(train_X, train_y)):\n","            l, a = train_step(model, img, lbl, LEARNING_RATE)\n","            epoch_loss += l\n","            epoch_acc += a\n","\n","            # In tiến độ mỗi 200 ảnh\n","            if i % 200 == 0:\n","                percent = (i / len(train_X)) * 100\n","                print(f\"\\r  Epoch {epoch+1} Running... {percent:.1f}%\", end=\"\")\n","\n","        # Tổng kết Epoch\n","        train_avg_loss = epoch_loss / len(train_X)\n","        train_avg_acc = (epoch_acc / len(train_X)) * 100\n","\n","        # Đánh giá trên tập Validation\n","        val_loss, val_acc = evaluate(model, val_X, val_y)\n","\n","        # Lưu history\n","        history['train_loss'].append(train_avg_loss)\n","        history['train_acc'].append(train_avg_acc)\n","        history['val_loss'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","\n","        print(f\"\\rEpoch {epoch+1:02d}/{EPOCHS} | \"\n","              f\"Train Loss: {train_avg_loss:.4f} Acc: {train_avg_acc:.2f}% | \"\n","              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}% | \"\n","              f\"Time: {time.time()-start_time:.1f}s\")\n","\n","    # 7. Lưu Model và Biểu đồ\n","    print(\"\\n[INFO] Đang lưu kết quả...\")\n","    model.save_model(MODEL_SAVE_PATH, idx_to_class)\n","    plot_history(history, MODEL_SAVE_DIR)\n","    print(\"\\n=== HOÀN TẤT ===\")\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"TlK5WUZCb6fa","outputId":"659251d2-2d45-4c12-e0d6-b00a5618c8b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["=== BẮT ĐẦU QUÁ TRÌNH TRAINING ===\n","Unzipping /content/drive/MyDrive/Colab/dataset/CNN_letter_Dataset.rar...\n","[INFO] Đang tìm thư mục dữ liệu...\n","[INFO] Đã tìm thấy dữ liệu tại: /content/dataset/CNN letter Dataset\n","[INFO] Đang load ảnh và nhãn từ /content/dataset/CNN letter Dataset...\n","[INFO] Đang chia dữ liệu (Validation Split = 0.2)...\n","--------------------------------------------------\n","Tổng số Class: 31\n","Dữ liệu Train: 25152 ảnh\n","Dữ liệu Valid: 6288 ảnh\n","Kích thước ảnh input: (28, 28)\n","--------------------------------------------------\n","Epoch 01/15 | Train Loss: 0.9724 Acc: 70.94% | Val Loss: 0.2021 Acc: 94.77% | Time: 994.1s\n","Epoch 02/15 | Train Loss: 0.3251 Acc: 89.65% | Val Loss: 0.0951 Acc: 97.57% | Time: 998.0s\n","Epoch 03/15 | Train Loss: 0.2147 Acc: 93.05% | Val Loss: 0.0628 Acc: 98.22% | Time: 996.8s\n","Epoch 04/15 | Train Loss: 0.1692 Acc: 94.45% | Val Loss: 0.0406 Acc: 98.92% | Time: 993.5s\n","Epoch 05/15 | Train Loss: 0.1305 Acc: 95.73% | Val Loss: 0.0337 Acc: 99.03% | Time: 995.7s\n","Epoch 06/15 | Train Loss: 0.1152 Acc: 96.25% | Val Loss: 0.0244 Acc: 99.20% | Time: 997.7s\n","Epoch 07/15 | Train Loss: 0.1074 Acc: 96.49% | Val Loss: 0.0237 Acc: 99.48% | Time: 994.3s\n","Epoch 08/15 | Train Loss: 0.0934 Acc: 96.89% | Val Loss: 0.0168 Acc: 99.57% | Time: 1006.0s\n","Epoch 09/15 | Train Loss: 0.0789 Acc: 97.43% | Val Loss: 0.0160 Acc: 99.57% | Time: 1005.5s\n","Epoch 10/15 | Train Loss: 0.0658 Acc: 97.74% | Val Loss: 0.0134 Acc: 99.65% | Time: 995.0s\n","Epoch 11/15 | Train Loss: 0.0626 Acc: 97.93% | Val Loss: 0.0121 Acc: 99.68% | Time: 997.9s\n","Epoch 12/15 | Train Loss: 0.0630 Acc: 97.92% | Val Loss: 0.0128 Acc: 99.68% | Time: 998.3s\n","Epoch 13/15 | Train Loss: 0.0523 Acc: 98.18% | Val Loss: 0.0121 Acc: 99.63% | Time: 1006.7s\n","Epoch 14/15 | Train Loss: 0.0516 Acc: 98.34% | Val Loss: 0.0102 Acc: 99.73% | Time: 1003.8s\n","Epoch 15/15 | Train Loss: 0.0469 Acc: 98.36% | Val Loss: 0.0108 Acc: 99.71% | Time: 999.4s\n","\n","[INFO] Đang lưu kết quả...\n","[SUCCESS] Saved model: /content/drive/MyDrive/Colab/model_output/my_cnn_model.npz\n","\n","[CHART] Đã lưu biểu đồ đánh giá tại: /content/drive/MyDrive/Colab/model_output/training_result_chart.png\n","\n","=== HOÀN TẤT ===\n"]}],"source":["!python train.py"]},{"cell_type":"code","source":["from google.colab import files\n","from PIL import Image as PILImage\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from model import CNNModel\n","import io\n","\n","# ===== CẤU HÌNH =====\n","MODEL_PATH = \"/content/drive/MyDrive/Colab/model_output/my_cnn_model.npz\"\n","\n","def predict_uploaded_image():\n","    # 1. Load Model trước\n","    model, idx_to_class = CNNModel.load_model(MODEL_PATH)\n","    if model is None: return\n","\n","    # 2. Cho user upload file\n","    print(\"Hay chon mot file anh chu cai (A-Z, 0-9) tu may tinh cua ban:\")\n","    uploaded = files.upload()\n","\n","    for fn in uploaded.keys():\n","        # 3. Xử lý ảnh upload\n","        image_data = uploaded[fn]\n","        img_pil = PILImage.open(io.BytesIO(image_data)).convert('L') # Chuyển sang đen trắng\n","\n","        # Resize về đúng kích thước model đã học (28x28)\n","        img_resized = img_pil.resize((28, 28), PILImage.LANCZOS)\n","        img_array = np.array(img_resized, dtype=np.float32) / 255.0 # Normalize\n","\n","        # 4. Dự đoán\n","        probs, _ = model.forward(img_array, training=False)\n","        pred_idx = np.argmax(probs)\n","        pred_label = idx_to_class[pred_idx]\n","        confidence = probs[pred_idx] * 100\n","\n","        # 5. Hiển thị kết quả\n","        plt.figure(figsize=(3, 3))\n","        plt.imshow(img_array, cmap='gray')\n","        plt.title(f\"Dự đoán: {pred_label}\\nĐộ tin cậy: {confidence:.1f}%\")\n","        plt.axis('off')\n","        plt.show()\n","        print(f\"-> File '{fn}' được nhận diện là: {pred_label}\")\n","\n","# Chạy hàm test upload\n","predict_uploaded_image()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"yid1lUGkDeWF","executionInfo":{"status":"ok","timestamp":1763674621421,"user_tz":-420,"elapsed":4103,"user":{"displayName":"Lộc “Leopard” Nguyễn","userId":"17234762684403330361"}},"outputId":"2827b444-0279-4357-ea8b-f25a78576727"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Hay chon mot file anh chu cai (A-Z, 0-9) tu may tinh cua ban:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-28ab9057-bd67-4389-8a08-40e8cbc26443\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-28ab9057-bd67-4389-8a08-40e8cbc26443\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving C.jpg to C.jpg\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 300x300 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["-> File 'C.jpg' được nhận diện là: 0\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqq+7y+jPVhtJMqGGsF/2a"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}